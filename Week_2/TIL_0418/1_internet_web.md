## 인터넷과 웹

LAN : 네트워크를 묶어 근거리 지역 네트워크 탄생
* 학교나 회사에서 구축된 LAN

범지구적으로 연결된 네트워크
* www = world wide web

> 인터넷은 여러 컴퓨터 끼리 네트워크를 연결한 것

> Web은 인터넷 상에서 정보를 교환하기 위한 시스템

### Web 상에서는 정보를 어떻게 주고 받을까?

* 클라이언트 : 정보를 요청
* 서버 : 정보를 제공

1. 클라이언트가 서버에게 정보를 요청
    * programmers.co.kr 정보 주세요
2. 잠시만요 .. !
    * 요청에 대해서 서버가 작업을 수행
3. 수행한 작업의 결과를 클라이언트에게 응답
    * 여기 있습니다! , 엥? 요청이 이상한데요?

### HTTP의 구조 
* 웹 상에서 정보를 주고받기 위한 약속
* 클라이언트 -> 서버로 정보를 요청 : `HTTP 요청 (Request)`
* Head : 보내는 사람 / 받는 사람
* Body : 내용물
* request
```text
GET / HTTTP 1.1
Host : www.programmers.com
User-Agent : Mozilla/5.0
```
* response
```text
HTTP/1.1 200 OK
<html> ... </html>
```

### 웹페이지와 HTML
* 웹사이드와 웹 페이지
    * 웹 속에 있는 문서 하나 : 웹 페이지
    * 이런 웹 페이지의 모음 : 웹 사이트

### 웹 페이지는 어떻게 만들까?
* 웹 페이지는 HTML이라는 형식으로 되어있고, 웹 브라우저는 우리가 HTTP요청을 보내고, 응답받은 HTML 코드를 렌더링 해주었다.
* 웹 브라우저마다 지원하는 속성이 다르다. 


## 윤리적으로 웹 스크래핑 / 크롤링 진행하기

웹 크롤링 ? / 웹 스크래핑 ? 두 단어의 차이는 무엇이지?
* 웹 스크래핑 : "추출"
    * 특정한 목적으로 특정 웹 페이지에서 데이터를 추출하는 것
    * 날씨 데이터 가져오기, 주식 데이터 가져오기 등
* 웹 크롤링 : 웹 페이지 정보를 인덱싱
    * URL을 타고 다니며, 반복적으로 데이터를 가져오는 과정 
    * 검색 엔진의 웹 크롤러

-> 우리 강의는 웹 스크래핑에 조금 더 가깝다!

### 올바르게 HTTP 요청하기
* 웹 스크래핑 / 크롤링을 통해 **어떤 목적** 을 달성하고자 하는가?
* 다른 웹 스크래핑 / 크롤링이 **서버에 영향**을 미치지 않는가?

-> 상업적으로 사용한다면 저작권, 데이터베이스 문제를 확인해야 함

### 로봇 배제 프로토콜 (REP)
웹 브라우징은 사람이 아니라, 로봇이 진행 가능
* 그렇다고 무턱대고 모든 사이트에 대해 모든 정보를 취득하는 것이 정당할까?
    * REP (Robot Exclusion Protocol)

* robots.txt
    * User-agent, Disallow, Allow 등의 키워드를 통해 사용
    * 웹 크롤러들은 이 규칙을 지키면서 크롤링을 진행
    ```text
    User-agent : *
    Disallow : /
    ```
    *  모든 user-agent에 대해 접근을 거부
    ```text
    User-agent : *
    Allow : /
    ```
    * 모든 user-agent에 대해 접근을 허가

## DOM  (Document Object Model)
> 브라우저에 대한 넓고 얕은 지식

* html > head > body : DOM
* 왜 브라우저는 DOM을 만들까?
    * 원하는 요소를 동적으로 변경해줄 수 있다.
    * 원하는 요소를 쉽게 찾을 수 있다.
    * 파이썬으로 HTM을 분석하는 HTML Parser가 필요하다.
